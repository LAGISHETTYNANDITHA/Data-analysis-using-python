{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LAGISHETTYNANDITHA/Data-analysis-using-python/blob/main/daup_proj_2(rgb_256)(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "rgb 256"
      ],
      "metadata": {
        "id": "exA02CDpSpmr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Define dataset paths\n",
        "train_dir = \"/content/drive/MyDrive/Meat Freshness.v1-new-dataset.multiclass/train\"\n",
        "val_dir = \"/content/drive/MyDrive/Meat Freshness.v1-new-dataset.multiclass/valid\"\n",
        "\n",
        "# Define label mapping\n",
        "label_mapping = {\"FRESH\": 0, \"SPOILED\": 1}\n",
        "\n",
        "# Function to extract label from filename\n",
        "def get_label_from_filename(filename):\n",
        "    if \"FRESH\" in filename.upper():\n",
        "        return label_mapping[\"FRESH\"]\n",
        "    elif \"SPOILED\" in filename.upper():\n",
        "        return label_mapping[\"SPOILED\"]\n",
        "    else:\n",
        "        return None  # Ignore unexpected filenames\n",
        "\n",
        "# Function to load images and labels\n",
        "def load_images(folder, img_size=(256, 256)):\n",
        "    images, labels = [], []\n",
        "\n",
        "    for file in os.listdir(folder):\n",
        "        img_path = os.path.join(folder, file)\n",
        "\n",
        "        label = get_label_from_filename(file)\n",
        "        if label is not None:\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is not None:\n",
        "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
        "                img = cv2.resize(img, img_size)  # Resize image\n",
        "                img = img / 255.0  # Normalize\n",
        "\n",
        "                images.append(img)\n",
        "                labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Load train and validation data\n",
        "X_train, y_train = load_images(train_dir, img_size=(256, 256))\n",
        "X_val, y_val = load_images(val_dir, img_size=(256, 256))\n",
        "\n",
        "print(f\"Loaded {len(X_train)} training images and {len(X_val)} validation images\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzBpifbPk4ks",
        "outputId": "c455399e-cd58-40b4-c615-69d4204f3f76"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 1815 training images and 451 validation images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "8hnQvfIxb2OK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25b5031b-caec-4771-d50d-64eacc5a81ef"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define CNN Model with 3 Convolutional Layers\n",
        "def build_cnn(input_shape):\n",
        "    model = keras.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(1, activation='sigmoid')  # Binary Classification (Fresh/Spoiled)\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Create and compile the model\n",
        "model = build_cnn((256, 256, 3))\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "print(\"Training the CNN...\")\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))\n",
        "\n",
        "# Evaluate model\n",
        "test_loss, test_acc = model.evaluate(X_val, y_val)\n",
        "print(f\"Validation Accuracy: {test_acc * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_B8vU2yr9No",
        "outputId": "aedc67cd-c21a-4116-eef0-8dac8db46961"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training the CNN...\n",
            "Epoch 1/10\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 212ms/step - accuracy: 0.7021 - loss: 0.7248 - val_accuracy: 0.8780 - val_loss: 0.2845\n",
            "Epoch 2/10\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 75ms/step - accuracy: 0.8995 - loss: 0.2501 - val_accuracy: 0.9290 - val_loss: 0.1552\n",
            "Epoch 3/10\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 0.9601 - loss: 0.1300 - val_accuracy: 0.8958 - val_loss: 0.2785\n",
            "Epoch 4/10\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 77ms/step - accuracy: 0.9523 - loss: 0.1282 - val_accuracy: 0.9579 - val_loss: 0.1075\n",
            "Epoch 5/10\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 78ms/step - accuracy: 0.9872 - loss: 0.0392 - val_accuracy: 0.9800 - val_loss: 0.0818\n",
            "Epoch 6/10\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 0.9824 - loss: 0.0337 - val_accuracy: 0.9601 - val_loss: 0.1356\n",
            "Epoch 7/10\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 0.9911 - loss: 0.0163 - val_accuracy: 0.9823 - val_loss: 0.0760\n",
            "Epoch 8/10\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - accuracy: 0.9974 - loss: 0.0089 - val_accuracy: 0.9845 - val_loss: 0.0706\n",
            "Epoch 9/10\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 72ms/step - accuracy: 0.9980 - loss: 0.0065 - val_accuracy: 0.9690 - val_loss: 0.0975\n",
            "Epoch 10/10\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 0.9905 - loss: 0.0281 - val_accuracy: 0.9734 - val_loss: 0.0671\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9822 - loss: 0.0440\n",
            "Validation Accuracy: 97.34%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "\n",
        "# Function to load and preprocess image from a URL or local path\n",
        "def preprocess_image(path, target_size=(256, 256)):\n",
        "    \"\"\"\n",
        "    Loads and preprocesses an image from a URL or local file path.\n",
        "\n",
        "    Args:\n",
        "        path (str): The URL or local file path of the image.\n",
        "        target_size (tuple): The desired size of the image (width, height).\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: The preprocessed image as a NumPy array.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Attempt to open the path as a URL\n",
        "        response = requests.get(path)\n",
        "        img = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
        "    except (requests.exceptions.MissingSchema, requests.exceptions.InvalidSchema):\n",
        "        # If it's not a valid URL, assume it's a local file path\n",
        "        img = Image.open(path).convert(\"RGB\")\n",
        "\n",
        "    img = img.resize(target_size)  # Resize image\n",
        "    img_array = np.array(img) / 255.0  # Normalize\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "    return img_array\n",
        "\n",
        "# Function to make a prediction\n",
        "def predict_image(path, model):\n",
        "    img_array = preprocess_image(path)\n",
        "    prediction = model.predict(img_array)[0][0]  # Get single prediction\n",
        "    if prediction > 0.5:\n",
        "        print(\"Prediction: ❌ Spoiled Meat\")\n",
        "    else:\n",
        "        print(\"Prediction: ✅ Fresh Meat\")\n",
        "\n",
        "# Example usage\n",
        "image_url = \"/content/drive/MyDrive/Meat Freshness.v1-new-dataset.multiclass/train/FRESH-1-_JPG.rf.65663691924ca0aede3884b863267c98.jpg\"  # Replace with actual image URL or local file path\n",
        "predict_image(image_url, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngCnFYFz44xA",
        "outputId": "4a0bb972-3016-4b8d-d677-1977b8c89fb8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 883ms/step\n",
            "Prediction: ✅ Fresh Meat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "greyscale 256"
      ],
      "metadata": {
        "id": "woSgpq9zSx1n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Define dataset paths\n",
        "train_dir = \"/content/drive/MyDrive/Meat Freshness.v1-new-dataset.multiclass/train\"\n",
        "val_dir = \"/content/drive/MyDrive/Meat Freshness.v1-new-dataset.multiclass/valid\"\n",
        "\n",
        "# Define label mapping\n",
        "label_mapping = {\"FRESH\": 0, \"SPOILED\": 1}\n",
        "\n",
        "# Function to extract label from filename\n",
        "def get_label_from_filename(filename):\n",
        "    if \"FRESH\" in filename.upper():\n",
        "        return label_mapping[\"FRESH\"]\n",
        "    elif \"SPOILED\" in filename.upper():\n",
        "        return label_mapping[\"SPOILED\"]\n",
        "    else:\n",
        "        return None  # Ignore unexpected filenames\n",
        "\n",
        "# Function to load images and labels (convert to grayscale)\n",
        "def load_images(folder, img_size=(256, 256)):\n",
        "    images, labels = [], []\n",
        "\n",
        "    for file in os.listdir(folder):\n",
        "        img_path = os.path.join(folder, file)\n",
        "\n",
        "        label = get_label_from_filename(file)\n",
        "        if label is not None:\n",
        "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Read image in grayscale\n",
        "            if img is not None:\n",
        "                img = cv2.resize(img, img_size)  # Resize image\n",
        "                img = img / 255.0  # Normalize\n",
        "\n",
        "                images.append(img)\n",
        "                labels.append(label)\n",
        "\n",
        "    return np.array(images).reshape(-1, img_size[0], img_size[1], 1), np.array(labels)  # Add channel dimension\n",
        "\n",
        "# Load train and validation data\n",
        "X_train, y_train = load_images(train_dir, img_size=(256, 256))\n",
        "X_val, y_val = load_images(val_dir, img_size=(256, 256))\n",
        "\n",
        "print(f\"Loaded {len(X_train)} training images and {len(X_val)} validation images\")\n"
      ],
      "metadata": {
        "id": "1yy3jZjaQtqu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ef0e4b5-e557-44d1-af27-4dee5ab8e2d1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 1815 training images and 451 validation images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import requests\n",
        "\n",
        "# Define dataset paths (Update paths as needed)\n",
        "train_dir = \"/content/drive/MyDrive/Meat Freshness.v1-new-dataset.multiclass/train\"\n",
        "val_dir = \"/content/drive/MyDrive/Meat Freshness.v1-new-dataset.multiclass/valid\"\n",
        "\n",
        "# Define label mapping\n",
        "label_mapping = {\"FRESH\": 0, \"SPOILED\": 1}\n",
        "\n",
        "# Function to extract label from filename\n",
        "def get_label_from_filename(filename):\n",
        "    if \"FRESH\" in filename.upper():\n",
        "        return label_mapping[\"FRESH\"]\n",
        "    elif \"SPOILED\" in filename.upper():\n",
        "        return label_mapping[\"SPOILED\"]\n",
        "    else:\n",
        "        return None  # Ignore unexpected filenames\n",
        "\n",
        "# Function to load grayscale images and labels\n",
        "def load_images(folder, img_size=(256, 256)):\n",
        "    images, labels = [], []\n",
        "\n",
        "    if not os.path.exists(folder):  # Check if directory exists\n",
        "        raise FileNotFoundError(f\"Directory not found: {folder}\")\n",
        "\n",
        "    for file in os.listdir(folder):\n",
        "        img_path = os.path.join(folder, file)\n",
        "\n",
        "        label = get_label_from_filename(file)\n",
        "        if label is not None:\n",
        "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load as grayscale\n",
        "            if img is not None:\n",
        "                img = cv2.resize(img, img_size)  # Resize image\n",
        "                img = img / 255.0  # Normalize\n",
        "                img = np.expand_dims(img, axis=-1)  # Add channel dimension (H, W, 1)\n",
        "\n",
        "                images.append(img)\n",
        "                labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Load train and validation data\n",
        "X_train, y_train = load_images(train_dir, img_size=(256, 256))\n",
        "X_val, y_val = load_images(val_dir, img_size=(256, 256))\n",
        "\n",
        "print(f\"Loaded {len(X_train)} training images and {len(X_val)} validation images\")\n",
        "\n",
        "# Define CNN Model for grayscale input\n",
        "def build_cnn(input_shape):\n",
        "    model = keras.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(1, activation='sigmoid')  # Binary Classification (Fresh/Spoiled)\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Create and compile the model\n",
        "model = build_cnn((256, 256, 1))  # Adjust input shape for grayscale\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "print(\"Training the CNN...\")\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))\n",
        "\n",
        "# Evaluate model\n",
        "test_loss, test_acc = model.evaluate(X_val, y_val)\n",
        "print(f\"Validation Accuracy: {test_acc * 100:.2f}%\")\n",
        "\n",
        "# Function to preprocess grayscale image for prediction\n",
        "def preprocess_image(path, target_size=(256, 256)):\n",
        "    \"\"\"\n",
        "    Loads and preprocesses a grayscale image from a URL or local file path.\n",
        "\n",
        "    Args:\n",
        "        path (str): The URL or local file path of the image.\n",
        "        target_size (tuple): The desired size of the image (width, height).\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: The preprocessed image as a NumPy array.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = requests.get(path)\n",
        "        img = Image.open(BytesIO(response.content)).convert(\"L\")  # Convert to grayscale\n",
        "    except (requests.exceptions.MissingSchema, requests.exceptions.InvalidSchema):\n",
        "        img = Image.open(path).convert(\"L\")  # Convert local file to grayscale\n",
        "\n",
        "    img = img.resize(target_size)  # Resize\n",
        "    img_array = np.array(img) / 255.0  # Normalize\n",
        "    img_array = np.expand_dims(img_array, axis=-1)  # Add channel dimension (H, W, 1)\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "    return img_array\n",
        "\n",
        "# Function to make a prediction\n",
        "def predict_image(path, model):\n",
        "    img_array = preprocess_image(path)\n",
        "    prediction = model.predict(img_array)[0][0]  # Get single prediction\n",
        "    if prediction > 0.5:\n",
        "        print(\"Prediction: ❌ Spoiled Meat\")\n",
        "    else:\n",
        "        print(\"Prediction: ✅ Fresh Meat\")\n",
        "\n",
        "# Example usage (Update with actual image path)\n",
        "image_path = \"/content/drive/MyDrive/Meat Freshness.v1-new-dataset.multiclass/train/FRESH-1-_JPG.rf.65663691924ca0aede3884b863267c98.jpg\"\n",
        "predict_image(image_path, model)\n"
      ],
      "metadata": {
        "id": "7uTcsdOPQ4i2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31ee446e-bc5c-4207-80ee-97a6d8631152"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 1815 training images and 451 validation images\n",
            "Training the CNN...\n",
            "Epoch 1/10\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 121ms/step - accuracy: 0.6886 - loss: 0.7337 - val_accuracy: 0.8027 - val_loss: 0.4326\n",
            "Epoch 2/10\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step - accuracy: 0.8407 - loss: 0.3730 - val_accuracy: 0.8714 - val_loss: 0.2882\n",
            "Epoch 3/10\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - accuracy: 0.9189 - loss: 0.2151 - val_accuracy: 0.9268 - val_loss: 0.1989\n",
            "Epoch 4/10\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step - accuracy: 0.9525 - loss: 0.1374 - val_accuracy: 0.9446 - val_loss: 0.1748\n",
            "Epoch 5/10\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - accuracy: 0.9713 - loss: 0.0957 - val_accuracy: 0.9268 - val_loss: 0.1816\n",
            "Epoch 6/10\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - accuracy: 0.9720 - loss: 0.0782 - val_accuracy: 0.9401 - val_loss: 0.1846\n",
            "Epoch 7/10\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step - accuracy: 0.9765 - loss: 0.0561 - val_accuracy: 0.9557 - val_loss: 0.2021\n",
            "Epoch 8/10\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - accuracy: 0.9918 - loss: 0.0277 - val_accuracy: 0.9557 - val_loss: 0.1667\n",
            "Epoch 9/10\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - accuracy: 0.9894 - loss: 0.0291 - val_accuracy: 0.9601 - val_loss: 0.1522\n",
            "Epoch 10/10\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - accuracy: 0.9891 - loss: 0.0269 - val_accuracy: 0.9623 - val_loss: 0.1663\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9737 - loss: 0.1108\n",
            "Validation Accuracy: 96.23%\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497ms/step\n",
            "Prediction: ✅ Fresh Meat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "rgb 200"
      ],
      "metadata": {
        "id": "0D0FHWAdS2x6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import requests\n",
        "\n",
        "# Define dataset paths\n",
        "train_dir = \"/content/drive/MyDrive/Meat Freshness.v1-new-dataset.multiclass/train\"\n",
        "val_dir = \"/content/drive/MyDrive/Meat Freshness.v1-new-dataset.multiclass/valid\"\n",
        "\n",
        "# Define label mapping\n",
        "label_mapping = {\"FRESH\": 0, \"SPOILED\": 1}\n",
        "\n",
        "# Function to extract label from filename\n",
        "def get_label_from_filename(filename):\n",
        "    if \"FRESH\" in filename.upper():\n",
        "        return label_mapping[\"FRESH\"]\n",
        "    elif \"SPOILED\" in filename.upper():\n",
        "        return label_mapping[\"SPOILED\"]\n",
        "    else:\n",
        "        return None  # Ignore unexpected filenames\n",
        "\n",
        "# Function to load images and labels\n",
        "def load_images(folder, img_size=(200, 200)):  # Changed image size to 200x200\n",
        "    images, labels = [], []\n",
        "\n",
        "    for file in os.listdir(folder):\n",
        "        img_path = os.path.join(folder, file)\n",
        "\n",
        "        label = get_label_from_filename(file)\n",
        "        if label is not None:\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is not None:\n",
        "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
        "                img = cv2.resize(img, img_size)  # Resize image to 200x200\n",
        "                img = img / 255.0  # Normalize\n",
        "\n",
        "                images.append(img)\n",
        "                labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Load train and validation data\n",
        "X_train, y_train = load_images(train_dir, img_size=(200, 200))\n",
        "X_val, y_val = load_images(val_dir, img_size=(200, 200))\n",
        "\n",
        "print(f\"Loaded {len(X_train)} training images and {len(X_val)} validation images\")\n",
        "\n",
        "# Define CNN Model with 3 Convolutional Layers\n",
        "def build_cnn(input_shape):\n",
        "    model = keras.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(1, activation='sigmoid')  # Binary Classification (Fresh/Spoiled)\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Create and compile the model\n",
        "model = build_cnn((200, 200, 3))  # Changed input shape to 200x200\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "print(\"Training the CNN...\")\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))\n",
        "\n",
        "# Evaluate model\n",
        "test_loss, test_acc = model.evaluate(X_val, y_val)\n",
        "print(f\"Validation Accuracy: {test_acc * 100:.2f}%\")\n",
        "\n",
        "# Function to load and preprocess image from a URL or local path\n",
        "def preprocess_image(path, target_size=(200, 200)):  # Changed target size to 200x200\n",
        "    \"\"\"\n",
        "    Loads and preprocesses an image from a URL or local file path.\n",
        "\n",
        "    Args:\n",
        "        path (str): The URL or local file path of the image.\n",
        "        target_size (tuple): The desired size of the image (width, height).\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: The preprocessed image as a NumPy array.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Attempt to open the path as a URL\n",
        "        response = requests.get(path)\n",
        "        img = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
        "    except (requests.exceptions.MissingSchema, requests.exceptions.InvalidSchema):\n",
        "        # If it's not a valid URL, assume it's a local file path\n",
        "        img = Image.open(path).convert(\"RGB\")\n",
        "\n",
        "    img = img.resize(target_size)  # Resize image to 200x200\n",
        "    img_array = np.array(img) / 255.0  # Normalize\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "    return img_array\n",
        "\n",
        "# Function to make a prediction\n",
        "def predict_image(path, model):\n",
        "    img_array = preprocess_image(path)\n",
        "    prediction = model.predict(img_array)[0][0]  # Get single prediction\n",
        "    if prediction > 0.5:\n",
        "        print(\"Prediction: ❌ Spoiled Meat\")\n",
        "    else:\n",
        "        print(\"Prediction: ✅ Fresh Meat\")\n",
        "\n",
        "# Example usage\n",
        "image_path = \"/content/drive/MyDrive/Meat Freshness.v1-new-dataset.multiclass/train/FRESH-1-_JPG.rf.65663691924ca0aede3884b863267c98.jpg\"  # Replace with actual image path\n",
        "predict_image(image_path, model)\n"
      ],
      "metadata": {
        "id": "HBWdJt9-SnIh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "986d1074-7283-4dba-b30f-0e60a6e7d339"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 1815 training images and 451 validation images\n",
            "Training the CNN...\n",
            "Epoch 1/10\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 163ms/step - accuracy: 0.7019 - loss: 0.7444 - val_accuracy: 0.8160 - val_loss: 0.4664\n",
            "Epoch 2/10\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8861 - loss: 0.2905 - val_accuracy: 0.8780 - val_loss: 0.2559\n",
            "Epoch 3/10\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9467 - loss: 0.1434 - val_accuracy: 0.9357 - val_loss: 0.1686\n",
            "Epoch 4/10\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - accuracy: 0.9689 - loss: 0.0908 - val_accuracy: 0.9667 - val_loss: 0.0920\n",
            "Epoch 5/10\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.9772 - loss: 0.0621 - val_accuracy: 0.9690 - val_loss: 0.1229\n",
            "Epoch 6/10\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.9800 - loss: 0.0521 - val_accuracy: 0.9601 - val_loss: 0.1674\n",
            "Epoch 7/10\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9877 - loss: 0.0480 - val_accuracy: 0.9778 - val_loss: 0.1042\n",
            "Epoch 8/10\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.9958 - loss: 0.0156 - val_accuracy: 0.9823 - val_loss: 0.0767\n",
            "Epoch 9/10\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - accuracy: 0.9969 - loss: 0.0091 - val_accuracy: 0.9823 - val_loss: 0.0820\n",
            "Epoch 10/10\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.9974 - loss: 0.0123 - val_accuracy: 0.9047 - val_loss: 0.3517\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8837 - loss: 0.3875\n",
            "Validation Accuracy: 90.47%\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 654ms/step\n",
            "Prediction: ✅ Fresh Meat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "greyscale 200"
      ],
      "metadata": {
        "id": "lgCo5BR8TQOw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import requests\n",
        "\n",
        "# Define dataset paths\n",
        "train_dir = \"/content/drive/MyDrive/Meat Freshness.v1-new-dataset.multiclass/train\"\n",
        "val_dir = \"/content/drive/MyDrive/Meat Freshness.v1-new-dataset.multiclass/valid\"\n",
        "\n",
        "# Define label mapping\n",
        "label_mapping = {\"FRESH\": 0, \"SPOILED\": 1}\n",
        "\n",
        "# Function to extract label from filename\n",
        "def get_label_from_filename(filename):\n",
        "    if \"FRESH\" in filename.upper():\n",
        "        return label_mapping[\"FRESH\"]\n",
        "    elif \"SPOILED\" in filename.upper():\n",
        "        return label_mapping[\"SPOILED\"]\n",
        "    else:\n",
        "        return None  # Ignore unexpected filenames\n",
        "\n",
        "# Function to load images and labels (convert to grayscale)\n",
        "def load_images(folder, img_size=(200, 200)):\n",
        "    images, labels = [], []\n",
        "\n",
        "    for file in os.listdir(folder):\n",
        "        img_path = os.path.join(folder, file)\n",
        "\n",
        "        label = get_label_from_filename(file)\n",
        "        if label is not None:\n",
        "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load as grayscale\n",
        "            if img is not None:\n",
        "                img = cv2.resize(img, img_size)  # Resize image to 200x200\n",
        "                img = img / 255.0  # Normalize\n",
        "\n",
        "                images.append(img)\n",
        "                labels.append(label)\n",
        "\n",
        "    return np.array(images).reshape(-1, 200, 200, 1), np.array(labels)  # Reshape for CNN\n",
        "\n",
        "# Load train and validation data\n",
        "X_train, y_train = load_images(train_dir, img_size=(200, 200))\n",
        "X_val, y_val = load_images(val_dir, img_size=(200, 200))\n",
        "\n",
        "print(f\"Loaded {len(X_train)} training images and {len(X_val)} validation images\")\n",
        "\n",
        "# Define CNN Model with 3 Convolutional Layers\n",
        "def build_cnn(input_shape):\n",
        "    model = keras.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(1, activation='sigmoid')  # Binary Classification (Fresh/Spoiled)\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Create and compile the model\n",
        "model = build_cnn((200, 200, 1))  # Changed input shape to (200, 200, 1) for grayscale\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "print(\"Training the CNN...\")\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))\n",
        "\n",
        "# Evaluate model\n",
        "test_loss, test_acc = model.evaluate(X_val, y_val)\n",
        "print(f\"Validation Accuracy: {test_acc * 100:.2f}%\")\n",
        "\n",
        "# Function to load and preprocess image from a URL or local path (convert to grayscale)\n",
        "def preprocess_image(path, target_size=(200, 200)):\n",
        "    \"\"\"\n",
        "    Loads and preprocesses an image from a URL or local file path.\n",
        "\n",
        "    Args:\n",
        "        path (str): The URL or local file path of the image.\n",
        "        target_size (tuple): The desired size of the image (width, height).\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: The preprocessed image as a NumPy array.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Attempt to open the path as a URL\n",
        "        response = requests.get(path)\n",
        "        img = Image.open(BytesIO(response.content)).convert(\"L\")  # Convert to grayscale\n",
        "    except (requests.exceptions.MissingSchema, requests.exceptions.InvalidSchema):\n",
        "        # If it's not a valid URL, assume it's a local file path\n",
        "        img = Image.open(path).convert(\"L\")  # Convert to grayscale\n",
        "\n",
        "    img = img.resize(target_size)  # Resize image to 200x200\n",
        "    img_array = np.array(img) / 255.0  # Normalize\n",
        "    img_array = np.expand_dims(img_array, axis=(0, -1))  # Add batch and channel dimensions\n",
        "    return img_array\n",
        "\n",
        "# Function to make a prediction\n",
        "def predict_image(path, model):\n",
        "    img_array = preprocess_image(path)\n",
        "    prediction = model.predict(img_array)[0][0]  # Get single prediction\n",
        "    if prediction > 0.5:\n",
        "        print(\"Prediction: ❌ Spoiled Meat\")\n",
        "    else:\n",
        "        print(\"Prediction: ✅ Fresh Meat\")\n",
        "\n",
        "# Example usage\n",
        "image_path = \"/content/drive/MyDrive/Meat Freshness.v1-new-dataset.multiclass/train/FRESH-1-_JPG.rf.65663691924ca0aede3884b863267c98.jpg\"\n",
        "predict_image(image_path, model)\n"
      ],
      "metadata": {
        "id": "bB_C9XCvTVh7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f73d4a1-042c-4da2-dec7-294707e85281"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 1815 training images and 451 validation images\n",
            "Training the CNN...\n",
            "Epoch 1/10\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - accuracy: 0.6690 - loss: 0.6887 - val_accuracy: 0.8625 - val_loss: 0.3858\n",
            "Epoch 2/10\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - accuracy: 0.8507 - loss: 0.3523 - val_accuracy: 0.9024 - val_loss: 0.2582\n",
            "Epoch 3/10\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 45ms/step - accuracy: 0.9352 - loss: 0.1730 - val_accuracy: 0.9357 - val_loss: 0.1799\n",
            "Epoch 4/10\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.9632 - loss: 0.0999 - val_accuracy: 0.9180 - val_loss: 0.2318\n",
            "Epoch 5/10\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.9721 - loss: 0.0768 - val_accuracy: 0.9468 - val_loss: 0.1466\n",
            "Epoch 6/10\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 46ms/step - accuracy: 0.9784 - loss: 0.0522 - val_accuracy: 0.9645 - val_loss: 0.1190\n",
            "Epoch 7/10\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.9900 - loss: 0.0348 - val_accuracy: 0.9557 - val_loss: 0.1125\n",
            "Epoch 8/10\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 45ms/step - accuracy: 0.9931 - loss: 0.0201 - val_accuracy: 0.9512 - val_loss: 0.1254\n",
            "Epoch 9/10\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 46ms/step - accuracy: 0.9987 - loss: 0.0080 - val_accuracy: 0.9645 - val_loss: 0.1245\n",
            "Epoch 10/10\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.9987 - loss: 0.0062 - val_accuracy: 0.9645 - val_loss: 0.1285\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9682 - loss: 0.1100\n",
            "Validation Accuracy: 96.45%\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385ms/step\n",
            "Prediction: ✅ Fresh Meat\n"
          ]
        }
      ]
    }
  ]
}